{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Pipeline\n",
    "---\n",
    "\n",
    "In this notebook we create a pipeline to forecast sales with the models we trained in the last step. We will set up the Pipeline for forecasting given the desired forecasting horizon. As we did with training, we utilize the [ParallelRunStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallel_run_step.parallelrunstep) to parallelize the process. For more information about the data and models refer to the previous notebooks. \n",
    "\n",
    "### Prerequisites\n",
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](01_Data_Preparation.ipynb) to create the dataset\n",
    "3. Run [02_Training_Pipeline.ipynb](02_Training_Pipeline.ipynb) to train the models\n",
    "\n",
    "Please ensure you have the latest version of the Azure ML SDK and also install Pipeline Steps Package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-sdk azureml-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Connect to workspace and datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Connect to workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get datastore\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "print('SDK version: ' + azureml.core.VERSION, \n",
    "      'Workspace Name: ' + ws.name,\n",
    "      'Azure Region: ' + ws.location,\n",
    "      'Subscription ID: ' + ws.subscription_id,\n",
    "      'Resource Group: ' + ws.resource_group,\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Get the test dataset\n",
    "\n",
    "In the [data preparation notebook](01_Data_Preparation.ipynb), we registered a subset of the orange juice for testing purposes. We will now get a reference to that dataset in our Datastore. We will use the models trained in the [modeling notebook](02_Training_Pipeline.ipynb) to generate forecasts over all rows in each test file.\n",
    "\n",
    "You can choose to run the pipeline on the subet of files or the full dataset of 11,973 series. If you chose to use only a subset of the files, the test dataset name will be `oj_data_small_test`. Otherwise, the name you'll have to use is `oj_data_test`. We recommend starting with the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'oj_data_small_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "dataset_input = dataset.as_named_input(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Choose a compute target\n",
    "\n",
    "This is the compute cluster you created in the [setup notebook](00_Setup_AML_Workspace.ipynb#3.0-Create-compute-cluster) and used for training in the [training notebook](02_Training_Pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster_name = 'cpucluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "compute = AmlCompute(ws, cpu_cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Build the forecasting pipeline\n",
    "\n",
    "As we did with the training pipeline, we'll create a ParallelRunStep to parallelize our forecasting process. You'll notice this code is essentially the same as the last step except that we'll be parallelizing [the forecasting script](scripts/forecast.py) rather than the training script. Note that we still need to pass the timeseries schema (timestamp column name, timeseries ID column names, etc) to the forecasting script. Unlike the training script, however, the name of target column is not required for the forecasting script, just optional. In a true forecasting scenario the actual values of the target are not available, of course, so the forecasting pipeline would just return predictions. In a testing scenario, the forecasting pipeline can also return the actuals, if the column name is provided, so that we may evaluate the accuracy of the forecasts on a hold-out set.\n",
    "\n",
    "### 4.1 Configure environment for ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option A] Environment for custom script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "customscript"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "forecast_env = Environment(name=\"many_models_environment_customscript\")\n",
    "forecast_conda_deps = CondaDependencies.create(\n",
    "    pip_packages=['sklearn', 'pandas', 'joblib', 'azureml-core', 'azureml-dataprep[fuse]'])\n",
    "forecast_env.python.conda_dependencies = forecast_conda_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option B] Environment for Automated ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "automl"
    ]
   },
   "outputs": [],
   "source": [
    "from scripts.notebooks.modeling import get_automl_environment\n",
    "forecast_env = get_automl_environment(name='many_models_environment_automl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Set up ParallelRunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option A] Configuration for custom script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "customscript"
    ]
   },
   "outputs": [],
   "source": [
    "node_count = 1\n",
    "process_count_per_node = 6\n",
    "run_invocation_timeout = 180\n",
    "forecasting_script = 'forecast.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option B] Configuration for Automated ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "automl"
    ]
   },
   "outputs": [],
   "source": [
    "node_count = 3\n",
    "process_count_per_node = 6\n",
    "run_invocation_timeout = 300\n",
    "forecasting_script = 'forecast_automl.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the `ParallelRunConfig` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig \n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./scripts',\n",
    "    entry_script=forecasting_script,\n",
    "    mini_batch_size='1',\n",
    "    run_invocation_timeout=run_invocation_timeout, \n",
    "    error_threshold=-1,\n",
    "    output_action='append_row', \n",
    "    environment=forecast_env, \n",
    "    process_count_per_node=process_count_per_node, \n",
    "    compute_target=compute, \n",
    "    node_count=node_count\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And validate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.notebooks.modeling import validate_parallel_run_config\n",
    "\n",
    "validate_parallel_run_config(parallel_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Set up ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option A] Parameters for custom script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "customscript"
    ]
   },
   "outputs": [],
   "source": [
    "step_arguments = [\n",
    "    '--target_column', 'Quantity',  # Since this is a testing scenario, pass the target column name \n",
    "    '--timestamp_column', 'WeekStarting', \n",
    "    '--timeseries_id_columns', 'Store', 'Brand',\n",
    "    '--model_type', 'lr'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Option B] Parameters for Automated ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "automl"
    ]
   },
   "outputs": [],
   "source": [
    "step_arguments = [\n",
    "    '--group_column_names', 'Store', 'Brand',\n",
    "    '--target_column_name', 'Quantity',  # This is optional, and needs to be passed only if inference data contains target column\n",
    "    '--time_column_name', 'WeekStarting'  # This is needed for timeseries\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the `ParallelRunStep` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import ParallelRunStep \n",
    "\n",
    "output_dir = PipelineData(name='forecasting_output', datastore=dstore)\n",
    "\n",
    "parallel_run_step = ParallelRunStep(\n",
    "    name=\"many-models-parallel-forecasting\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[dataset_input],\n",
    "    output=output_dir,\n",
    "    allow_reuse=False,\n",
    "    arguments=step_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Create step to copy predictions\n",
    "\n",
    "The forecasting pipeline includes a second step that copies the predictions from *parallel_run_step.txt* to a CSV file in a separate container. While this step is simple, it demonstates how a step can be added to the pipeline to upload the predictions to a separate datastore or make additional transformations to the output.\n",
    "\n",
    "First, we create a datastore named **predictions** to hold the outputs of the pipeline and get a reference to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "output_dstore = Datastore.register_azure_blob_container(\n",
    "    workspace=ws, \n",
    "    datastore_name='predictions',\n",
    "    container_name='predictions',\n",
    "    account_name=dstore.account_name,\n",
    "    account_key=dstore.account_key,\n",
    "    create_if_not_exists=True\n",
    ")\n",
    "\n",
    "output_dref = DataReference(output_dstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the [PythonScriptStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep) and give it our newly create datastore as well as the location of the *parallel_run_step.txt*. Note that the copy script also uses the timeseries schema; the reason is that the copy script creates a header row for the prediction data and, thus, needs to know the column names. The target column is passed here only if it was also passed to the forecasting script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "upload_predictions_step = PythonScriptStep(\n",
    "    name='copy_predictions',\n",
    "    script_name='copy_predictions.py',\n",
    "    compute_target=compute,\n",
    "    source_directory='./scripts',\n",
    "    inputs=[output_dref, output_dir],\n",
    "    allow_reuse=False,\n",
    "    arguments=['--parallel_run_step_output', output_dir,\n",
    "               '--output_dir', output_dref,\n",
    "               '--target_column', 'Quantity',\n",
    "               '--timestamp_column', 'WeekStarting',\n",
    "               '--timeseries_id_columns', 'Store', 'Brand']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create the forecasting pipeline, composed of the ParallelRunStep that will issue forecasts in parallel, and the PythonScriptStep that will copy the predictions into a different Azure Blob Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallel_run_step, upload_predictions_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Run the forecasting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'many-models-forecasting')\n",
    "print('Experiment name: ' + experiment.name)\n",
    "\n",
    "run = experiment.submit(pipeline)\n",
    "print('Run ID:', run.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you did during training, you can run the folowing command if you'd like to monitor the forecasting process in jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False, raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 View the results of the forecasting pipeline\n",
    "\n",
    "The forecasting pipeline forecasts the orange juice quantity for a Store by Brand. To see our forecasts, we download the *parallel_run_step.txt*, read the results into a dataframe, and visualize the predictions. Note that we could also download the results from the predictions container we created above.\n",
    "\n",
    "### 6.1 Download parallel_run_step.txt locally\n",
    "You need to wait until run that was submitted to Azure Machine Learning Compute Cluster is complete. You can monitor the run status in the [Azure Machine Learning Portal](https://ml.azure.com).\n",
    "\n",
    "If this notebook has been restarted since you launched forecasting, you might need to run the following to get the `run` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Experiment\n",
    "# from azureml.pipeline.core import PipelineRun\n",
    "\n",
    "# experiment = Experiment(ws, 'many-models-forecasting')\n",
    "# run = PipelineRun(experiment, '<your-run-id>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then download the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_predictions(run, target_dir=None, step_name='many-models-parallel-forecasting', output_name='forecasting_output'):\n",
    "    stitch_run = run.find_step_run(step_name)[0]\n",
    "    port_data = stitch_run.get_output_data(output_name)\n",
    "    port_data.download(target_dir, show_progress=True, overwrite=True)\n",
    "    return os.path.join(target_dir, 'azureml', stitch_run.id, output_name)\n",
    "\n",
    "file_path = download_predictions(run, 'output')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Convert the file to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path + '/parallel_run_step.txt', \n",
    "                 sep=' ',\n",
    "                 names=['Store', 'Brand', 'WeekStarting', 'Predictions', 'Quantity'], \n",
    "                 parse_dates=['WeekStarting'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualize the predictions\n",
    "First, we look at the distribution of predicted quantities by brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = sns.violinplot(x=df['Brand'], y=df['Predictions'], data=df)\n",
    "fig.set_title('Predictions by Brand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we look at those predictions over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "week = df.groupby(['WeekStarting', 'Brand'])\n",
    "week = week['Predictions'].sum()\n",
    "week = pd.DataFrame(week.unstack(level=1))\n",
    "\n",
    "week.plot()\n",
    "plt.title('Total Predictions by Brand')\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Total Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, we can trim the results to look at individual brands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store = 1001\n",
    "df_1001 = df[df['Store'] == store]\n",
    "\n",
    "brands = df_1001.groupby(['WeekStarting','Brand'])\n",
    "brands= brands['Predictions'].sum()\n",
    "brands= pd.DataFrame(brands.unstack(level=1))\n",
    "\n",
    "brands.plot()\n",
    "plt.legend(loc='upper right', labels=brands.columns.values)\n",
    "plt.xticks(rotation=40)\n",
    "plt.title('Predictions for Store 1001')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Predicted Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we produced forecasts on a test set, we can also examine forecast errors. The next plot displays the distribution of absolute percentage errors for each date in the testing period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the absolute percentage error for each forecast at each date\n",
    "# Warning: percentage errors are not defined if the actuals contain zero values\n",
    "df['APE'] = 100*np.abs((df['Quantity'] - df['Predictions']) / df['Quantity'])\n",
    "\n",
    "fig = sns.boxplot(x='WeekStarting', y='APE', data=df)\n",
    "fig.set_title('Absolute Percentage Error Distributions Over All Stores and Brands')\n",
    "plt.gcf().set_size_inches(15.0, 6.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to see the error distributions broken down by store and brand. Here, the boxplots show the distribution of errors over time in the forecast period for each series in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.boxplot(x='Store', y='APE', hue='Brand', data=df)\n",
    "fig.set_title('Absolute Percentage Errors by Store and Brand')\n",
    "plt.gcf().set_size_inches(15.0, 6.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 *[Optional]* Publish and schedule the pipeline\n",
    "\n",
    "\n",
    "### 7.1 Publish the pipeline\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(\n",
    "#     name='many-models-forecasting',\n",
    "#     description='Many Models forecasting pipeline',\n",
    "#     version='1',\n",
    "#     continue_on_step_failure=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically issue forecasts every week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# training_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(\n",
    "#     ws, \n",
    "#     name=\"forecasting_pipeline_recurring_schedule\", \n",
    "#     description=\"Schedule Forecasting Pipeline to run on the first day of every week\",\n",
    "#     pipeline_id=training_pipeline_id, \n",
    "#     experiment_name=experiment.name, \n",
    "#     recurrence=recurrence\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "roastala"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
